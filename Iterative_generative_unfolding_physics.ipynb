{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import time\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "from scipy.stats import binned_statistic\n",
    "\n",
    "from models import CFM\n",
    "from models import Flow, FlowSubtraction\n",
    "from models import Classifier\n",
    "from omnifold_dataset import OmniFoldDataset\n",
    "from plots import plot_naive_unfold, plot_reweighted_distribution, plot_prior_unfold, SetStyle\n",
    "SetStyle()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OmniFold Example, let's load the following datasets:\n",
    "1. Reco-level simulation\n",
    "2. Gen-level simulation\n",
    "3. Background simulation\n",
    "4. Reco-level data\n",
    "5. Gen-level data\n",
    "6. Background data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "data_params = { \"path\": \"./\",\n",
    "                \"n_dim\": 6,\n",
    "                \"n_mc\": 100000,               \n",
    "                \"n_data\": 100000,                \n",
    "                \"n_background\": 10000,                \n",
    "                \"empty_value\": -5.0,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "OmniModel = OmniFoldDataset(data_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define background subtraction flow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "bkg_mc = OmniModel.mc_background_rec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "flow_params = {\"hidden_layers\": 6,\n",
    "               \"internal_size\": 128,\n",
    "               \"lr\": 1.e-5,\n",
    "               \"n_epochs\" : 500,\n",
    "               \"batch_size\" : 256,\n",
    "               \"batch_size_sample\": 2000}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "background_generator = Flow(dims_x = data_params['n_dim'], dims_c = 0,params = flow_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training generative model for 500 epochs with lr 1e-05\n",
      "    Finished epoch 0 with average loss 28.045175552368164 after time 1.8\n"
     ]
    }
   ],
   "source": [
    "background_generator.train(bkg_mc,weights = torch.ones_like(bkg_mc[:,0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "generated_background = background_generator.evaluate(num_evts = OmniModel.mc_background_rec.size(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "y_true = plt.hist(OmniModel.mc_background_rec[:,0].cpu().detach().numpy(),bins = 60,label = \"True background\", histtype='step')\n",
    "y_gen = plt.hist(generated_background[:,0].cpu().detach().numpy(),bins = 60,label = \"Generated background\", histtype='step')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "if not os.path.exists(\"Plots\"):\n",
    "    os.makedirs(\"Plots\")\n",
    "\n",
    "with PdfPages(f\"Plots/background_generated.pdf\") as out:\n",
    "    plot_reweighted_distribution(out, \n",
    "                                 ToyModel.mc_background_rec[:,0].cpu().detach().numpy(),\n",
    "                                 generated_background[:,0].cpu().detach().numpy(),\n",
    "                                 np.random.normal(0, 1.0, size=ToyModel.mc_background_rec[:,0].size(0)),\n",
    "                                 range=[-3,4], labels=[r\"true background\" , \"gaussian\", \"background generated\",], name=\"x_1\")    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "signal_generator = FlowSubtraction(dims_x = data_params['n_dim'], dims_c = 0,params = flow_params,\n",
    "                                   background_model = background_generator.network,\n",
    "                                   bkg_fraction = data_params[\"n_background\"]*1.0/(data_params[\"n_data\"] +  data_params[\"n_background\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "signal_generator.train(ToyModel.data_rec[ToyModel.data_rec_mask.bool()],weights = torch.ones_like(ToyModel.data_rec[ToyModel.data_rec_mask.bool()][:,0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate the signal and generate empty events at reco level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_data_reco = ToyModel.data_signal_rec[:,0][ToyModel.data_rec_mask[:data_params[\"n_data\"]].bool()].size(0)\n",
    "generated_signal = signal_generator.evaluate(num_evts = num_data_reco) #N*(1-delta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = plt.hist(ToyModel.data_signal_rec[:,0][ToyModel.data_rec_mask[:data_params[\"n_data\"]].bool()].cpu().detach().numpy(),bins = 60, range = [-5.5,4],label = \"True signal\", histtype='step')\n",
    "y_gen = plt.hist(generated_signal[:,0].cpu().detach().numpy(),bins = 60, range = [-5.5,4],label = \"Generated signal\", histtype='step')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "num_data_empty = num_data_reco*data_params['acceptance']/(1.0 - data_params['acceptance']) #N*(1-delta)*epsilon/(1-epsilon)\n",
    "#Add the empty events to the generated signals\n",
    "generated_signal = torch.cat([generated_signal,data_params[\"empty_value\"]*torch.ones_like(generated_signal[:int(num_data_empty)])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(f\"Number of expected signal events in the data {generated_signal.size(0)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Acceptance classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "acceptance_true = ToyModel.mc_rec[(ToyModel.mc_rec_mask.bool()) & (ToyModel.mc_gen_mask.bool())]\n",
    "acceptance_false = ToyModel.mc_rec[(ToyModel.mc_rec_mask.bool()) & ~(ToyModel.mc_gen_mask.bool())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "acceptance_classifier_params = { \"hidden_layers\": 4,\n",
    "                                 \"internal_size\": 64,\n",
    "                                 \"lr\": 1.e-4,\n",
    "                                 \"n_epochs\" : 30,\n",
    "                                 \"batch_size\" : 128,\n",
    "                                 \"batch_size_sample\": 2000\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "acceptance_classifier = Classifier(dims_in=1, params=acceptance_classifier_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "acceptance_classifier.train_classifier(acceptance_true, acceptance_false, balanced=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train efficiency classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "efficiency_classifier_params = { \"hidden_layers\": 4,\n",
    "                                 \"internal_size\": 64,\n",
    "                                 \"lr\": 1.e-4,\n",
    "                                 \"n_epochs\" : 30,\n",
    "                                 \"batch_size\" : 128,\n",
    "                                 \"batch_size_sample\": 2000\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "efficiency_true = ToyModel.mc_gen[(ToyModel.mc_rec_mask.bool()) & (ToyModel.mc_gen_mask.bool())]\n",
    "efficiency_false = ToyModel.mc_gen[~(ToyModel.mc_rec_mask.bool()) & (ToyModel.mc_gen_mask.bool())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "efficiency_classifier = Classifier(dims_in = 1, params = efficiency_classifier_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "efficiency_classifier.train_classifier(efficiency_true, efficiency_false, balanced=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Let's train the detector response flow p(reco|gen) and the initial p(gen) flows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "gen_generator = Flow(dims_x = data_params['n_dim'], dims_c = 0,params = flow_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "gen_generator.train(ToyModel.mc_gen[ToyModel.mc_gen_mask.bool()],weights = torch.ones_like(ToyModel.mc_gen[ToyModel.mc_gen_mask.bool()][:,0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "y_true = plt.hist(ToyModel.mc_gen[:,0][ToyModel.mc_gen_mask.bool()].cpu().detach().numpy(),\n",
    "                  bins = 60, range = [-5.5,4],label = \"MC gen signal\", histtype='step')\n",
    "y_gen = plt.hist(gen_generator.evaluate(num_evts = ToyModel.mc_gen[ToyModel.mc_gen_mask.bool()].size(0)).cpu().detach().numpy(),\n",
    "                 bins = 60, range = [-5.5,4],label = \"Generated gen signal\", histtype='step')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "detector_generator = Flow(dims_x = data_params['n_dim'], dims_c = data_params['n_dim'],params = flow_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "detector_generator.train(ToyModel.mc_rec[ToyModel.mc_rec_mask.bool()],\n",
    "                         weights = torch.ones_like(ToyModel.mc_rec[ToyModel.mc_rec_mask.bool()][:,0]), \n",
    "                         data_c = ToyModel.mc_gen[ToyModel.mc_rec_mask.bool()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "y_true = plt.hist(ToyModel.mc_rec[:,0][ToyModel.mc_rec_mask.bool()].cpu().detach().numpy(),\n",
    "                  bins = 60, range = [-5.5,4],label = \"MC reco signal\", histtype='step')\n",
    "y_gen = plt.hist(detector_generator.evaluate(data_c = ToyModel.mc_gen[ToyModel.mc_rec_mask.bool()]).cpu().detach().numpy(),\n",
    "                 bins = 60, range = [-5.5,4],label = \"Generated MC reco signal\", histtype='step')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Start the unfolding!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_reco(nevts,empty_fraction, efficiency_classifier,detector_model,gen_model):\n",
    "    ''' Generates h(reco|gen) samples by sampling from: h(reco|gen) = c(gen) + (1-c(gen))*p(reco|gen)*p(gen) '''\n",
    "    gen_events = gen_model.evaluate(num_evts = nevts)\n",
    "    gen_mask = ToyModel.apply_efficiency_acceptance_effects(gen_events,empty_fraction)\n",
    "    gen_events[~gen_mask.bool()] = data_params[\"empty_value\"]*torch.ones_like(gen_events[~gen_mask.bool()])\n",
    "    \n",
    "    efficiency = efficiency_classifier.evaluate(gen_events, return_weights=False)\n",
    "    sample_efficiency = torch.bernoulli(efficiency)\n",
    "    \n",
    "    reco_events = detector_model.evaluate(data_c=gen_events)\n",
    "    reco_events[~sample_efficiency.bool()] = data_params[\"empty_value\"]*torch.ones_like(gen_events[~sample_efficiency.bool()])\n",
    "    return  reco_events, gen_events, gen_mask "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "iterations = 5\n",
    "unfold_generator =  Flow(dims_x = data_params['n_dim'], dims_c = data_params['n_dim'],params = flow_params)\n",
    "for i in range(iterations):\n",
    "    print(f\"Running iteration {i}\")\n",
    "    reco_train, gen_train, gen_mask = sample_reco(data_params['n_mc'], \n",
    "                                                 data_params['efficiency'],\n",
    "                                                 efficiency_classifier,\n",
    "                                                 detector_generator,\n",
    "                                                 gen_generator)\n",
    "    unfold_generator.train(gen_train[gen_mask.bool()], \n",
    "                           weights = torch.ones_like(gen_train[gen_mask.bool()][:,0]), \n",
    "                           data_c = reco_train[gen_mask.bool()])\n",
    "    unfolded = unfold_generator.evaluate(data_c=generated_signal)\n",
    "    gen_generator.train(unfolded,weights = torch.ones_like(unfolded[:,0]))\n",
    "    #FIXME: Probably need to update the efficiency classifier here\n",
    "    fig, axes = plt.subplots()\n",
    "    axes.hist(unfolded[:,0].cpu().detach().numpy(), bins=60, histtype=\"step\", range=[-5.5,4],label=\"Gen. Unfolded\",density=True)\n",
    "    axes.hist(ToyModel.mc_gen[:,0][ToyModel.mc_gen_mask.bool()].cpu().detach().numpy(),bins=60, histtype='step', range=[-5.5,4],label=\"Gen. MC\",density=True)\n",
    "    axes.hist(ToyModel.data_gen[:,0][ToyModel.data_gen_mask.bool()].cpu().detach().numpy(), \n",
    "              bins=60, range=[-5.5,4], histtype=\"step\", label=\"Gen. Truth pass all\",density=True)\n",
    "    plt.legend()  # Display the legend\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fix Acceptance with empty true events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "acceptance = acceptance_classifier.evaluate(generated_signal, return_weights=False)\n",
    "acceptance_mask = torch.bernoulli(acceptance)\n",
    "unfolded = unfolded[acceptance_mask.bool()]\n",
    "print(f\"Unfolded true events {unfolded.size(0)}, Number of true data events {torch.sum(ToyModel.data_gen_mask.bool())}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with PdfPages(f\"Plots/final_generative_unfolding.pdf\") as out:\n",
    "    plot_naive_unfold(out, \n",
    "                      ToyModel.data_gen[:, 0][ToyModel.data_gen_mask.bool()].cpu().detach().numpy(),\n",
    "                      ToyModel.data_rec[:, 0][ToyModel.data_rec_mask.bool()].cpu().detach().numpy(),\n",
    "                      unfolded[:, 0].cpu().detach().numpy(),\n",
    "                      range=[-3, 4], name=\"x_1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch-2.1.0",
   "language": "python",
   "name": "pytorch-2.1.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
