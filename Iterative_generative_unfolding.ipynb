{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import time\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "from scipy.stats import binned_statistic\n",
    "\n",
    "from models import CFM\n",
    "from models import Classifier\n",
    "from gaussian_toy import GaussianToy\n",
    "from plots import plot_naive_unfold, plot_reweighted_distribution, plot_prior_unfold, SetStyle\n",
    "SetStyle()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import sys\n",
    "for h in logging.root.handlers[:]:\n",
    "    logging.root.removeHandler(h)\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    stream=sys.stdout,\n",
    "    format=\"%(asctime)s %(levelname)s %(message)s\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Gaussian toy example. Define six datasets:\n",
    "1. Reco-level simulation\n",
    "2. Gen-level simulation\n",
    "3. Background simulation\n",
    "4. Reco-level data\n",
    "5. Gen-level data\n",
    "6. Background data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "device = 'cuda'\n",
    "data_params = { \"n_dim\": 1,\n",
    "                \"n_mc\": 1_000_000,\n",
    "                \"mc_mu\": 0,\n",
    "                \"mc_sigma\": 1,\n",
    "                \"n_data\": 1_000_000,\n",
    "                \"data_mu\": 0.2,\n",
    "                \"data_sigma\": 0.8,\n",
    "                \"detector_mu\": 0,\n",
    "                \"detector_sigma\": 0.5,\n",
    "                \"n_background\": 100_000,\n",
    "                \"background_mu\": 0,\n",
    "                \"background_sigma\": 1.2,\n",
    "                \"mc_rec_cut\": True,\n",
    "                \"mc_gen_cut\": True,\n",
    "                \"data_rec_cut\": True,\n",
    "                \"data_gen_cut\": True ,\n",
    "                \"efficiency\": 0.1,\n",
    "                \"acceptance\": 0.1,\n",
    "                \"empty_value\": -5.0,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "ToyModel = GaussianToy(data_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define background subtraction CFM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "bkg_mc = ToyModel.mc_background_rec\n",
    "data_rec = ToyModel.data_rec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "generator_params = {\"hidden_layers\": 4,\n",
    "                   \"internal_size\": 64,\n",
    "                   \"lr\": 1.e-5,\n",
    "                   \"n_epochs\" : 100,\n",
    "                   \"batch_size\" : 128,\n",
    "                   \"batch_size_sample\": 2000}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "signal_generator = CFM(data_params['n_dim'], 0, generator_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "weights = torch.cat([torch.ones_like(data_rec[ToyModel.data_rec_mask.bool(),0]),\n",
    "                     -torch.ones_like(bkg_mc[:,0])])\n",
    "data = torch.cat([data_rec[ToyModel.data_rec_mask.bool()], bkg_mc], 0)\n",
    "signal_generator.train(data, weights=weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate the signal and generate empty events at reco level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_data_reco = ToyModel.data_signal_rec[:,0][ToyModel.data_rec_mask[:data_params[\"n_data\"]].bool()].size(0)\n",
    "generated_signal = signal_generator.evaluate(num_evts = num_data_reco,device = device) #N*(1-delta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = plt.hist(ToyModel.data_signal_rec[:,0][ToyModel.data_rec_mask[:data_params[\"n_data\"]].bool()].cpu().detach().numpy(),bins = 60, range = [-5.5,4],label = \"True signal\", histtype='step')\n",
    "y_gen = plt.hist(generated_signal[:,0].cpu().detach().numpy(),bins = 60, range = [-5.5,4],label = \"Generated signal\", histtype='step')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "num_data_empty = num_data_reco*data_params['acceptance']/(1.0 - data_params['acceptance']) #N*(1-delta)*epsilon/(1-epsilon)\n",
    "#Add the empty events to the generated signals\n",
    "generated_signal = torch.cat([generated_signal,data_params[\"empty_value\"]*torch.ones_like(generated_signal[:int(num_data_empty)])])\n",
    "signal_mask = generated_signal[:,0] != data_params[\"empty_value\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(f\"Number of expected signal events in the data {generated_signal.size(0)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Acceptance classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "acceptance_true = ToyModel.mc_rec[(ToyModel.mc_rec_mask.bool()) & (ToyModel.mc_gen_mask.bool())]\n",
    "acceptance_false = ToyModel.mc_rec[(ToyModel.mc_rec_mask.bool()) & ~(ToyModel.mc_gen_mask.bool())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "acceptance_classifier_params = { \"hidden_layers\": 4,\n",
    "                                 \"internal_size\": 64,\n",
    "                                 \"lr\": 3.e-5,\n",
    "                                 \"n_epochs\" : 30,\n",
    "                                 \"batch_size\" : 128,\n",
    "                                 \"batch_size_sample\": 2000\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "acceptance_classifier = Classifier(dims_in=1, params=acceptance_classifier_params,model_name=\"acceptance classifier\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "acceptance_classifier.train_classifier(acceptance_true, acceptance_false, balanced=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train efficiency classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "efficiency_classifier_params = { \"hidden_layers\": 4,\n",
    "                                 \"internal_size\": 64,\n",
    "                                 \"lr\": 1.e-4,\n",
    "                                 \"n_epochs\" : 30,\n",
    "                                 \"batch_size\" : 128,\n",
    "                                 \"batch_size_sample\": 2000\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "efficiency_true = ToyModel.mc_gen[(ToyModel.mc_rec_mask.bool()) & (ToyModel.mc_gen_mask.bool())]\n",
    "efficiency_false = ToyModel.mc_gen[~(ToyModel.mc_rec_mask.bool()) & (ToyModel.mc_gen_mask.bool())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "efficiency_classifier = Classifier(dims_in = 1, params = efficiency_classifier_params,model_name=\"efficiency classifier\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "efficiency_classifier.train_classifier(efficiency_true, efficiency_false, balanced=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Let's train the detector response flow p(reco|gen) and the initial p(gen) flows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "gen_generator = CFM(dims_x = data_params['n_dim'], dims_c = 0,params = generator_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "gen_generator.train(ToyModel.mc_gen[ToyModel.mc_gen_mask.bool()],weights = torch.ones_like(ToyModel.mc_gen[ToyModel.mc_gen_mask.bool()][:,0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "y_true = plt.hist(ToyModel.mc_gen[:,0][ToyModel.mc_gen_mask.bool()].cpu().detach().numpy(),\n",
    "                  bins = 60, range = [-5.5,4],label = \"MC gen signal\", histtype='step')\n",
    "y_gen = plt.hist(gen_generator.evaluate(num_evts = ToyModel.mc_gen[ToyModel.mc_gen_mask.bool()].size(0),device=device).cpu().detach().numpy(),\n",
    "                 bins = 60, range = [-5.5,4],label = \"Generated gen signal\", histtype='step')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "detector_generator = CFM(dims_x = data_params['n_dim'], dims_c = data_params['n_dim'],params = generator_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "detector_generator.train(ToyModel.mc_rec[ToyModel.mc_rec_mask.bool()],\n",
    "                         weights = torch.ones_like(ToyModel.mc_rec[ToyModel.mc_rec_mask.bool()][:,0]), \n",
    "                         data_c = ToyModel.mc_gen[ToyModel.mc_rec_mask.bool()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "y_true = plt.hist(ToyModel.mc_rec[:,0][ToyModel.mc_rec_mask.bool()].cpu().detach().numpy(),\n",
    "                  bins = 60, range = [-5.5,4],label = \"MC reco signal\", histtype='step')\n",
    "y_gen = plt.hist(detector_generator.evaluate(data_c = ToyModel.mc_gen[ToyModel.mc_rec_mask.bool()]).cpu().detach().numpy(),\n",
    "                 bins = 60, range = [-5.5,4],label = \"Generated MC reco signal\", histtype='step')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Start the unfolding!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_reco(nevts,empty_fraction, efficiency_classifier,detector_model,gen_model):\n",
    "    ''' Generates h(reco|gen) samples by sampling from: h(reco|gen) = c(gen) + (1-c(gen))*p(reco|gen)*p(gen) '''\n",
    "    gen_events = gen_model.evaluate(num_evts = nevts,device=device)\n",
    "    gen_mask = ToyModel.apply_efficiency_acceptance_effects(gen_events,empty_fraction)\n",
    "    #By definition generated events are within acceptance\n",
    "    gen_events = gen_events[gen_mask.bool()] \n",
    "    efficiency = efficiency_classifier.evaluate(gen_events, return_weights=False)\n",
    "    sample_efficiency = torch.bernoulli(efficiency)\n",
    "\n",
    "\n",
    "    num_data_empty = nevts*data_params['efficiency']/(1.0 - data_params['efficiency']) #N*(1-delta)*epsilon/(1-epsilon)\n",
    "    gen_events = torch.cat([gen_events,\n",
    "                            data_params[\"empty_value\"] * torch.ones_like(gen_events[: int(num_data_empty)])])\n",
    "    gen_mask = gen_events[:,0] != data_params[\"empty_value\"] \n",
    "    \n",
    "    #By definition, events not passing gen should pass reco\n",
    "    sample_efficiency = torch.cat(\n",
    "        [sample_efficiency,\n",
    "         torch.ones_like(sample_efficiency[:int(num_data_empty)])]\n",
    "        )\n",
    "    \n",
    "    reco_events = detector_model.evaluate(data_c=gen_events)\n",
    "    reco_events[~sample_efficiency.bool()] = data_params[\"empty_value\"]*torch.ones_like(gen_events[~sample_efficiency.bool()])\n",
    "    return  reco_events, gen_events, gen_mask, sample_efficiency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "iterations = 5\n",
    "unfold_generator =  CFM(dims_x = data_params['n_dim'], dims_c = data_params['n_dim'],params = generator_params)\n",
    "for i in range(iterations):\n",
    "    print(f\"Running iteration {i}\")\n",
    "    reco_train, gen_train, gen_mask, reco_mask = sample_reco(data_params['n_mc'], \n",
    "                                                             data_params['efficiency'],\n",
    "                                                             efficiency_classifier,\n",
    "                                                             detector_generator,\n",
    "                                                             gen_generator)\n",
    "    unfold_generator.train(gen_train[gen_mask.bool()], \n",
    "                           weights = torch.ones_like(gen_train[gen_mask.bool()][:,0]), \n",
    "                           data_c = reco_train[gen_mask.bool()])\n",
    "    \n",
    "    #Update the acceptance model\n",
    "    acceptance_classifier.train_classifier(\n",
    "                reco_train[(reco_mask.bool()) & (gen_mask.bool())],\n",
    "                reco_train[(reco_mask.bool()) & ~(gen_mask.bool())], balanced=False\n",
    "            )\n",
    "    acceptance = torch.cat([acceptance_classifier.evaluate(generated_signal[signal_mask.bool()], return_weights=False),\n",
    "                            torch.ones_like(generated_signal[~signal_mask.bool()][:,0])],-1)    \n",
    "    acceptance_mask = torch.bernoulli(acceptance)\n",
    "    \n",
    "    #Generate unfolded events\n",
    "    unfolded = unfold_generator.evaluate(data_c=generated_signal)\n",
    "    \n",
    "    #Train generator model after applying the acceptance model\n",
    "    gen_generator.train(unfolded[acceptance_mask.bool()], weights=torch.ones_like(unfolded[:, 0][acceptance_mask.bool()]))\n",
    "\n",
    "    fig, axes = plt.subplots()\n",
    "    axes.hist(unfolded[:,0].cpu().detach().numpy(), bins=60, histtype=\"step\", range=[-5.5,4],label=\"Gen. Unfolded\",density=True)\n",
    "    axes.hist(ToyModel.mc_gen[:,0][ToyModel.mc_gen_mask.bool()].cpu().detach().numpy(),bins=60, histtype='step', range=[-5.5,4],label=\"Gen. MC\",density=True)\n",
    "    axes.hist(ToyModel.data_gen[:,0][ToyModel.data_gen_mask.bool()].cpu().detach().numpy(), \n",
    "              bins=60, range=[-5.5,4], histtype=\"step\", label=\"Gen. Truth\",density=True)\n",
    "    plt.legend()  # Display the legend\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with PdfPages(f\"Plots/final_generative_unfolding.pdf\") as out:\n",
    "    plot_naive_unfold(out, \n",
    "                      ToyModel.data_gen[:, 0][ToyModel.data_gen_mask.bool()].cpu().detach().numpy(),\n",
    "                      ToyModel.data_rec[:, 0][ToyModel.data_rec_mask.bool()].cpu().detach().numpy(),\n",
    "                      unfolded[:, 0].cpu().detach().numpy(),\n",
    "                      range=[-3, 4], name=\"x_1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch-2.1.0",
   "language": "python",
   "name": "pytorch-2.1.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
